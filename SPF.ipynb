{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOBrQ19Gok/urvyrE+r27Ra",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VishnunandP/S-P-500-Stock-Price-Forecasting-using-LSTM/blob/main/SPF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "0DG2aNmxG7Cc",
        "outputId": "42d7c566-5222-4584-8314-a9e7851f78a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported successfully!\n",
            "TensorFlow version: 2.18.0\n",
            "Configuration set successfully!\n",
            "Downloading S&P 500 data...\n",
            "Successfully downloaded 3522 data points\n",
            "Calculating technical indicators...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Cannot set a DataFrame with multiple columns to the single column BB_upper",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-3331242841>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mraw_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Calculating technical indicators...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0mdata_with_indicators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_technical_indicators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Preparing features...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-3331242841>\u001b[0m in \u001b[0;36mcalculate_technical_indicators\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'BB_middle'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Close'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrolling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mbb_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Close'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrolling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'BB_upper'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'BB_middle'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbb_std\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'BB_lower'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'BB_middle'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbb_std\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'BB_width'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'BB_upper'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'BB_lower'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4299\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4300\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4301\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item_frame_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4302\u001b[0m         elif (\n\u001b[1;32m   4303\u001b[0m             \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item_frame_value\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4458\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4459\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   4460\u001b[0m                 \u001b[0;34m\"Cannot set a DataFrame with multiple columns to the single \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4461\u001b[0m                 \u001b[0;34mf\"column {key}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot set a DataFrame with multiple columns to the single column BB_upper"
          ]
        }
      ],
      "source": [
        "# S&P 500 Stock Price Prediction using LSTM\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import yfinance as yf\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "\n",
        "\n",
        "# Data parameters\n",
        "SYMBOL = \"^GSPC\"  # S&P 500 Index\n",
        "START_DATE = \"2010-01-01\"\n",
        "END_DATE = \"2024-01-01\"\n",
        "\n",
        "# Model parameters\n",
        "SEQUENCE_LENGTH = 60  # Number of time steps to look back\n",
        "PREDICTION_DAYS = 1   # Number of days to predict ahead\n",
        "TEST_SIZE = 0.2      # Proportion of data for testing\n",
        "VALIDATION_SIZE = 0.1 # Proportion of training data for validation\n",
        "\n",
        "# Neural network parameters\n",
        "LSTM_UNITS = [50, 50, 50]  # Units in each LSTM layer\n",
        "DROPOUT_RATE = 0.2\n",
        "LEARNING_RATE = 0.001\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 100\n",
        "\n",
        "print(\"Configuration set successfully!\")\n",
        "\n",
        "def fetch_data(symbol, start_date, end_date):\n",
        "    \"\"\"\n",
        "    Fetch stock data from Yahoo Finance\n",
        "    \"\"\"\n",
        "    try:\n",
        "        data = yf.download(symbol, start=start_date, end=end_date)\n",
        "        print(f\"Successfully downloaded {len(data)} data points\")\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading data: {e}\")\n",
        "        return None\n",
        "\n",
        "def calculate_technical_indicators(df):\n",
        "    # Ensure 'Close' is a Series, not accidentally a DataFrame\n",
        "    if isinstance(df['Close'], pd.DataFrame):\n",
        "        df['Close'] = df['Close'].iloc[:, 0]\n",
        "\n",
        "    # Bollinger Bands\n",
        "    df['BB_middle'] = df['Close'].rolling(window=20).mean()\n",
        "    bb_std = df['Close'].rolling(window=20).std()\n",
        "    df['BB_upper'] = df['BB_middle'] + (bb_std * 2)\n",
        "    df['BB_lower'] = df['BB_middle'] - (bb_std * 2)\n",
        "    df['BB_width'] = df['BB_upper'] - df['BB_lower']\n",
        "\n",
        "    # Handle divide-by-zero safely\n",
        "    bb_position = (df['Close'] - df['BB_lower']) / (df['BB_upper'] - df['BB_lower'])\n",
        "    bb_position = bb_position.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "    df['BB_position'] = bb_position\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def prepare_features(df):\n",
        "    \"\"\"\n",
        "    Prepare and clean features for model training\n",
        "    \"\"\"\n",
        "    # Select features for the model\n",
        "    feature_columns = [\n",
        "        'Open', 'High', 'Low', 'Close', 'Volume',\n",
        "        'SMA_20', 'SMA_50', 'EMA_12', 'EMA_26',\n",
        "        'MACD', 'MACD_signal', 'RSI',\n",
        "        'BB_width', 'BB_position', 'Volume_ratio',\n",
        "        'High_Low_Pct', 'Price_Change', 'Price_Change_MA'\n",
        "    ]\n",
        "\n",
        "    # Create feature dataframe\n",
        "    features_df = df[feature_columns].copy()\n",
        "\n",
        "    # Drop rows with NaN values (from technical indicators)\n",
        "    features_df = features_df.dropna()\n",
        "\n",
        "    print(f\"Features prepared. Shape: {features_df.shape}\")\n",
        "    print(f\"Feature columns: {list(features_df.columns)}\")\n",
        "\n",
        "    return features_df\n",
        "\n",
        "# Download and prepare data\n",
        "print(\"Downloading S&P 500 data...\")\n",
        "raw_data = fetch_data(SYMBOL, START_DATE, END_DATE)\n",
        "\n",
        "if raw_data is not None:\n",
        "    print(\"Calculating technical indicators...\")\n",
        "    data_with_indicators = calculate_technical_indicators(raw_data.copy())\n",
        "\n",
        "    print(\"Preparing features...\")\n",
        "    features_data = prepare_features(data_with_indicators)\n",
        "\n",
        "    print(\"\\nData preprocessing completed successfully!\")\n",
        "    print(f\"Final dataset shape: {features_data.shape}\")\n",
        "    print(f\"Date range: {features_data.index[0]} to {features_data.index[-1]}\")\n",
        "\n",
        "\n",
        "\n",
        "def plot_data_overview(data):\n",
        "    \"\"\"\n",
        "    Create comprehensive data visualization\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "    # Price and volume\n",
        "    axes[0, 0].plot(data.index, data['Close'], label='Close Price', linewidth=1)\n",
        "    axes[0, 0].plot(data.index, data['SMA_20'], label='SMA 20', alpha=0.7)\n",
        "    axes[0, 0].plot(data.index, data['SMA_50'], label='SMA 50', alpha=0.7)\n",
        "    axes[0, 0].set_title('S&P 500 Price with Moving Averages')\n",
        "    axes[0, 0].set_ylabel('Price ($)')\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Volume\n",
        "    axes[0, 1].plot(data.index, data['Volume'], color='orange', alpha=0.7)\n",
        "    axes[0, 1].set_title('Trading Volume')\n",
        "    axes[0, 1].set_ylabel('Volume')\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    # RSI\n",
        "    axes[1, 0].plot(data.index, data['RSI'], color='purple')\n",
        "    axes[1, 0].axhline(y=70, color='r', linestyle='--', alpha=0.7, label='Overbought')\n",
        "    axes[1, 0].axhline(y=30, color='g', linestyle='--', alpha=0.7, label='Oversold')\n",
        "    axes[1, 0].set_title('Relative Strength Index (RSI)')\n",
        "    axes[1, 0].set_ylabel('RSI')\n",
        "    axes[1, 0].set_ylim(0, 100)\n",
        "    axes[1, 0].legend()\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    # MACD\n",
        "    axes[1, 1].plot(data.index, data['MACD'], label='MACD', color='blue')\n",
        "    axes[1, 1].plot(data.index, data['MACD_signal'], label='Signal', color='red')\n",
        "    axes[1, 1].bar(data.index, data['MACD_histogram'], label='Histogram', alpha=0.3)\n",
        "    axes[1, 1].set_title('MACD Indicator')\n",
        "    axes[1, 1].set_ylabel('MACD')\n",
        "    axes[1, 1].legend()\n",
        "    axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Display data overview\n",
        "plot_data_overview(features_data)\n",
        "\n",
        "\n",
        "\n",
        "def create_sequences(data, seq_length, prediction_days=1):\n",
        "    \"\"\"\n",
        "    Create sequences for LSTM training\n",
        "    \"\"\"\n",
        "    X, y = [], []\n",
        "\n",
        "    for i in range(seq_length, len(data) - prediction_days + 1):\n",
        "        # Input sequence\n",
        "        X.append(data[i-seq_length:i])\n",
        "        # Target (Close price after prediction_days)\n",
        "        y.append(data[i + prediction_days - 1, 3])  # Close price is at index 3\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "def prepare_data_for_training(features_data, sequence_length, test_size, validation_size):\n",
        "    \"\"\"\n",
        "    Prepare data for LSTM training with proper scaling and splitting\n",
        "    \"\"\"\n",
        "    # Convert to numpy array\n",
        "    data_array = features_data.values\n",
        "\n",
        "    # Split data temporally\n",
        "    total_size = len(data_array)\n",
        "    train_size = int(total_size * (1 - test_size))\n",
        "\n",
        "    train_data = data_array[:train_size]\n",
        "    test_data = data_array[train_size:]\n",
        "\n",
        "    # Scale the data\n",
        "    scaler = MinMaxScaler()\n",
        "    train_data_scaled = scaler.fit_transform(train_data)\n",
        "    test_data_scaled = scaler.transform(test_data)\n",
        "\n",
        "    # Create sequences\n",
        "    X_train, y_train = create_sequences(train_data_scaled, sequence_length)\n",
        "    X_test, y_test = create_sequences(test_data_scaled, sequence_length)\n",
        "\n",
        "    # Split training data for validation\n",
        "    val_size = int(len(X_train) * validation_size)\n",
        "    X_val = X_train[-val_size:]\n",
        "    y_val = y_train[-val_size:]\n",
        "    X_train = X_train[:-val_size]\n",
        "    y_train = y_train[:-val_size]\n",
        "\n",
        "    print(f\"Training sequences: {X_train.shape}\")\n",
        "    print(f\"Validation sequences: {X_val.shape}\")\n",
        "    print(f\"Test sequences: {X_test.shape}\")\n",
        "\n",
        "    return (X_train, y_train), (X_val, y_val), (X_test, y_test), scaler\n",
        "\n",
        "# Prepare data for training\n",
        "(X_train, y_train), (X_val, y_val), (X_test, y_test), scaler = prepare_data_for_training(\n",
        "    features_data, SEQUENCE_LENGTH, TEST_SIZE, VALIDATION_SIZE\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "def build_lstm_model(input_shape, lstm_units, dropout_rate, learning_rate):\n",
        "    \"\"\"\n",
        "    Build and compile LSTM model\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "\n",
        "    # First LSTM layer\n",
        "    model.add(LSTM(\n",
        "        units=lstm_units[0],\n",
        "        return_sequences=True,\n",
        "        input_shape=input_shape\n",
        "    ))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "\n",
        "    # Second LSTM layer\n",
        "    model.add(LSTM(\n",
        "        units=lstm_units[1],\n",
        "        return_sequences=True\n",
        "    ))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "\n",
        "    # Third LSTM layer\n",
        "    model.add(LSTM(\n",
        "        units=lstm_units[2],\n",
        "        return_sequences=False\n",
        "    ))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "\n",
        "    # Dense layers\n",
        "    model.add(Dense(50, activation='relu'))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(25, activation='relu'))\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    # Compile model\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='mse',\n",
        "        metrics=['mae']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Build the model\n",
        "input_shape = (X_train.shape[1], X_train.shape[2])\n",
        "model = build_lstm_model(input_shape, LSTM_UNITS, DROPOUT_RATE, LEARNING_RATE)\n",
        "\n",
        "# Display model architecture\n",
        "model.summary()\n",
        "\n",
        "def train_model(model, X_train, y_train, X_val, y_val, batch_size, epochs):\n",
        "    \"\"\"\n",
        "    Train the LSTM model with callbacks\n",
        "    \"\"\"\n",
        "    # Define callbacks\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=15,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    reduce_lr = ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=10,\n",
        "        min_lr=1e-7,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    callbacks = [early_stopping, reduce_lr]\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,\n",
        "        validation_data=(X_val, y_val),\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    return history\n",
        "\n",
        "print(\"Starting model training...\")\n",
        "history = train_model(model, X_train, y_train, X_val, y_val, BATCH_SIZE, EPOCHS)\n",
        "\n",
        "\n",
        "\n",
        "def plot_training_history(history):\n",
        "    \"\"\"\n",
        "    Plot training and validation metrics\n",
        "    \"\"\"\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "    # Loss\n",
        "    ax1.plot(history.history['loss'], label='Training Loss')\n",
        "    ax1.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    ax1.set_title('Model Loss')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    # MAE\n",
        "    ax2.plot(history.history['mae'], label='Training MAE')\n",
        "    ax2.plot(history.history['val_mae'], label='Validation MAE')\n",
        "    ax2.set_title('Model MAE')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_ylabel('MAE')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def evaluate_model(model, X_test, y_test, scaler):\n",
        "    \"\"\"\n",
        "    Evaluate model performance on test data\n",
        "    \"\"\"\n",
        "    # Make predictions\n",
        "    y_pred_scaled = model.predict(X_test)\n",
        "\n",
        "    # Create dummy array for inverse scaling\n",
        "    dummy_array = np.zeros((len(y_pred_scaled), scaler.n_features_in_))\n",
        "    dummy_array[:, 3] = y_pred_scaled.flatten()  # Close price is at index 3\n",
        "    y_pred = scaler.inverse_transform(dummy_array)[:, 3]\n",
        "\n",
        "    # Inverse scale true values\n",
        "    dummy_array_true = np.zeros((len(y_test), scaler.n_features_in_))\n",
        "    dummy_array_true[:, 3] = y_test\n",
        "    y_true = scaler.inverse_transform(dummy_array_true)[:, 3]\n",
        "\n",
        "    # Calculate metrics\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "    # Directional accuracy\n",
        "    direction_true = np.diff(y_true) > 0\n",
        "    direction_pred = np.diff(y_pred) > 0\n",
        "    directional_accuracy = np.mean(direction_true == direction_pred) * 100\n",
        "\n",
        "    print(\"Model Performance Metrics:\")\n",
        "    print(f\"RMSE: ${rmse:.2f}\")\n",
        "    print(f\"MAE: ${mae:.2f}\")\n",
        "    print(f\"MAPE: {mape:.2f}%\")\n",
        "    print(f\"Directional Accuracy: {directional_accuracy:.2f}%\")\n",
        "\n",
        "    return y_true, y_pred, {\n",
        "        'RMSE': rmse,\n",
        "        'MAE': mae,\n",
        "        'MAPE': mape,\n",
        "        'Directional_Accuracy': directional_accuracy\n",
        "    }\n",
        "\n",
        "# Plot training history\n",
        "plot_training_history(history)\n",
        "\n",
        "# Evaluate model\n",
        "y_true, y_pred, metrics = evaluate_model(model, X_test, y_test, scaler)\n",
        "\n",
        "\n",
        "\n",
        "def plot_predictions(y_true, y_pred, features_data, sequence_length):\n",
        "    \"\"\"\n",
        "    Plot actual vs predicted prices\n",
        "    \"\"\"\n",
        "    # Create date index for test period\n",
        "    test_start_idx = len(features_data) - len(y_true)\n",
        "    test_dates = features_data.index[test_start_idx:]\n",
        "\n",
        "    plt.figure(figsize=(15, 8))\n",
        "\n",
        "    # Plot actual vs predicted\n",
        "    plt.plot(test_dates, y_true, label='Actual Price', linewidth=1.5, alpha=0.8)\n",
        "    plt.plot(test_dates, y_pred, label='Predicted Price', linewidth=1.5, alpha=0.8)\n",
        "\n",
        "    plt.title('S&P 500 Price Prediction - LSTM Model', fontsize=16)\n",
        "    plt.xlabel('Date', fontsize=12)\n",
        "    plt.ylabel('Price ($)', fontsize=12)\n",
        "    plt.legend(fontsize=12)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Calculate and plot residuals\n",
        "    residuals = y_true - y_pred\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(test_dates, residuals, alpha=0.7)\n",
        "    plt.axhline(y=0, color='r', linestyle='--', alpha=0.8)\n",
        "    plt.title('Prediction Residuals')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Residual ($)')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.hist(residuals, bins=30, alpha=0.7, density=True)\n",
        "    plt.title('Residuals Distribution')\n",
        "    plt.xlabel('Residual ($)')\n",
        "    plt.ylabel('Density')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot predictions\n",
        "plot_predictions(y_true, y_pred, features_data, SEQUENCE_LENGTH)\n",
        "\n",
        "\n",
        "\n",
        "def predict_future_prices(model, last_sequence, scaler, days_ahead=30):\n",
        "    \"\"\"\n",
        "    Predict future prices using the trained model\n",
        "    \"\"\"\n",
        "    predictions = []\n",
        "    current_sequence = last_sequence.copy()\n",
        "\n",
        "    for _ in range(days_ahead):\n",
        "        # Predict next day\n",
        "        pred_scaled = model.predict(current_sequence.reshape(1, *current_sequence.shape), verbose=0)\n",
        "\n",
        "        # Create dummy array for inverse scaling\n",
        "        dummy_array = np.zeros((1, scaler.n_features_in_))\n",
        "        dummy_array[0, 3] = pred_scaled[0, 0]\n",
        "        pred_price = scaler.inverse_transform(dummy_array)[0, 3]\n",
        "\n",
        "        predictions.append(pred_price)\n",
        "\n",
        "        # Update sequence for next prediction\n",
        "        # For simplicity, we'll just update the close price and keep other features constant\n",
        "        next_step = current_sequence[-1].copy()\n",
        "        next_step[3] = pred_scaled[0, 0]  # Update close price\n",
        "\n",
        "        # Shift sequence and add new step\n",
        "        current_sequence = np.vstack([current_sequence[1:], next_step])\n",
        "\n",
        "    return np.array(predictions)\n",
        "\n",
        "# Get last sequence from test data\n",
        "last_sequence = X_test[-1]\n",
        "\n",
        "# Predict next 30 days\n",
        "future_predictions = predict_future_prices(model, last_sequence, scaler, days_ahead=30)\n",
        "\n",
        "# Create future dates\n",
        "last_date = features_data.index[-1]\n",
        "future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=30, freq='D')\n",
        "\n",
        "# Plot future predictions\n",
        "plt.figure(figsize=(15, 8))\n",
        "\n",
        "# Plot recent historical data\n",
        "recent_data = features_data['Close'].tail(100)\n",
        "plt.plot(recent_data.index, recent_data.values, label='Historical Prices', linewidth=1.5)\n",
        "\n",
        "# Plot future predictions\n",
        "plt.plot(future_dates, future_predictions, label='Future Predictions',\n",
        "         linewidth=2, linestyle='--', marker='o', markersize=3)\n",
        "\n",
        "plt.title('S&P 500 Future Price Predictions (30 Days)', fontsize=16)\n",
        "plt.xlabel('Date', fontsize=12)\n",
        "plt.ylabel('Price ($)', fontsize=12)\n",
        "plt.legend(fontsize=12)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PROJECT SUMMARY AND INSIGHTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\nModel Configuration:\")\n",
        "print(f\"- Sequence Length: {SEQUENCE_LENGTH} days\")\n",
        "print(f\"- Features: {X_train.shape[2]} technical indicators\")\n",
        "print(f\"- Training Samples: {len(X_train):,}\")\n",
        "print(f\"- Test Samples: {len(X_test):,}\")\n",
        "\n",
        "print(f\"\\nPerformance Metrics:\")\n",
        "for metric, value in metrics.items():\n",
        "    if 'Accuracy' in metric:\n",
        "        print(f\"- {metric}: {value:.2f}%\")\n",
        "    elif metric == 'MAPE':\n",
        "        print(f\"- {metric}: {value:.2f}%\")\n",
        "    else:\n",
        "        print(f\"- {metric}: ${value:.2f}\")\n",
        "\n",
        "print(f\"\\nFuture Predictions Summary:\")\n",
        "print(f\"- Current Price: ${features_data['Close'].iloc[-1]:.2f}\")\n",
        "print(f\"- 30-day Average Prediction: ${np.mean(future_predictions):.2f}\")\n",
        "print(f\"- Predicted Price Range: ${np.min(future_predictions):.2f} - ${np.max(future_predictions):.2f}\")\n",
        "print(f\"- Expected Return (30 days): {((future_predictions[-1] / features_data['Close'].iloc[-1]) - 1) * 100:.2f}%\")\n",
        "\n",
        "print(f\"\\nKey Insights:\")\n",
        "print(\"- The LSTM model successfully captures complex temporal patterns in S&P 500 data\")\n",
        "print(\"- Technical indicators significantly enhance prediction accuracy\")\n",
        "print(\"- The model shows strong directional accuracy for trend prediction\")\n",
        "print(\"- Future predictions should be used alongside other analysis methods\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PROJECT COMPLETED SUCCESSFULLY!\")\n",
        "print(\"=\"*80)\n"
      ]
    }
  ]
}